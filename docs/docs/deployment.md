### Deployment of the model

### since we want low-latency prediction  we used async service instead of sync service

![](..)



